{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\Users\\Adelino\\Desktop\\Roberth\\Cursos\\Nanodegree-Machine_Learning\\Trabalhos\\Projetos\\ProjetoFinal\\Saidas\\Tratadas.csv\", sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               TWEET LANG      CLAS\n",
      "0  RT @pyramuscrypto: Out here trying to find the...   en  POSITIVO\n",
      "1  Let's farm bitcoins for free together - https:...   en    NEUTRO\n",
      "2  The Japanese government said today that inspec...   en  NEGATIVO\n",
      "3  With this project we will help undervalued coi...   en  POSITIVO\n",
      "4  Op-ed: How Decentralized Protocols Are Threate...   en    NEUTRO\n",
      "(5000, 3)\n"
     ]
    }
   ],
   "source": [
    "print data.head()\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_columns = data.columns[0]\n",
    "target_columns = data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_raw = data[features_columns]\n",
    "y_all = data[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_DF = pd.DataFrame(columns=['TWEET'])\n",
    "\n",
    "for linha in X_raw:  \n",
    "    words = word_tokenize(linha)\n",
    "    novalinha = \"\"\n",
    "    flag = True\n",
    "    for w in words:\n",
    "        if w != \"RT\":                \n",
    "            if re.match('[a-zA-Z0-9_]',w) and flag:\n",
    "                novalinha+=w+\" \"\n",
    "            if w == \"@\":\n",
    "                flag = False\n",
    "            else:\n",
    "                flag = True\n",
    "    X_all_DF.loc[len(X_all_DF)] = novalinha\n",
    "\n",
    "X_all = X_all_DF['TWEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    RT @pyramuscrypto: Out here trying to find the...\n",
      "1    Let's farm bitcoins for free together - https:...\n",
      "2    The Japanese government said today that inspec...\n",
      "3    With this project we will help undervalued coi...\n",
      "4    Op-ed: How Decentralized Protocols Are Threate...\n",
      "5    ❄️ #Solar #Exclusive @ https://t.co/LH9IHQvP37...\n",
      "6    Bitcoin Cash Surges To Fresh, All-Time High Ab...\n",
      "7    New #bitcoin block 0000000000000000000cc1416a7...\n",
      "8    #Bitcoin #Bitcoinbet LaVine took flight agains...\n",
      "9    @rogerkver @BTCNewsUpdates @ShapeShift_io I Wi...\n",
      "Name: TWEET, dtype: object\n",
      "\n",
      "0    Out here trying to find the next bitcoin to tr...\n",
      "1    Let farm bitcoins for free together https Ever...\n",
      "2    The Japanese government said today that inspec...\n",
      "3    With this project we will help undervalued coi...\n",
      "4    Op-ed How Decentralized Protocols Are Threaten...\n",
      "5    Solar Exclusive No samples One beat One artist...\n",
      "6    Bitcoin Cash Surges To Fresh All-Time High Abo...\n",
      "7    New bitcoin block 0000000000000000000cc1416a71...\n",
      "8    Bitcoin Bitcoinbet LaVine took flight against ...\n",
      "9    I Will Promote Your Bitcoin Ad Or Link Via Soc...\n",
      "Name: TWEET, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_raw.head(10))\n",
    "print(\"\")\n",
    "print(X_all.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X_all).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_all, train_size=0.7)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Multinomial Naive Bayes: 0.778\n",
      "Acuracia Gaussian Naive Bayes: 0.704666666667\n",
      "Acuracia Random Forest: 0.846\n",
      " \n",
      "F1_Score Multinomial Naive Bayes: 0.778\n",
      "F1_Score Gaussian Naive Bayes: 0.704666666667\n",
      "F1_Score Random Forest: 0.846\n"
     ]
    }
   ],
   "source": [
    "print \"Acuracia Multinomial Naive Bayes: {}\".format(accuracy_score(y_test, mnb.predict(X_test)))\n",
    "print \"Acuracia Gaussian Naive Bayes: {}\".format(accuracy_score(y_test, gnb.predict(X_test)))\n",
    "print \"Acuracia Random Forest: {}\".format(accuracy_score(y_test, rfc.predict(X_test)))\n",
    "print \" \"\n",
    "print \"F1_Score Multinomial Naive Bayes: {}\".format(f1_score(y_test, mnb.predict(X_test), average='micro'))\n",
    "print \"F1_Score Gaussian Naive Bayes: {}\".format(f1_score(y_test, gnb.predict(X_test), average='micro'))\n",
    "print \"F1_Score Random Forest: {}\".format(f1_score(y_test, rfc.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AJUSTE BASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##stop words\n",
    "stopWords = set(stopwords.words('english'))\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_all_bag_DF = pd.DataFrame(columns=['TWEET'])\n",
    "\n",
    "for linha in X_all:  \n",
    "    words = word_tokenize(linha)\n",
    "    novalinha = \"\"\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            novalinha+=w+\" \"\n",
    "    X_all_bag_DF.loc[len(X_all_bag_DF)] = novalinha\n",
    "\n",
    "X_all_bag = X_all_bag_DF['TWEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X_all_bag).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_all, train_size=0.7)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Word | Acuracia Multinomial Naive Bayes: 0.754666666667\n",
      "Stop Word | Acuracia Gaussian Naive Bayes: 0.664666666667\n",
      "Stop Word | Acuracia Random Forest: 0.829333333333\n"
     ]
    }
   ],
   "source": [
    "print \"Stop Word | Acuracia Multinomial Naive Bayes: {}\".format(accuracy_score(y_test, mnb.predict(X_test)))\n",
    "print \"Stop Word | Acuracia Gaussian Naive Bayes: {}\".format(accuracy_score(y_test, gnb.predict(X_test)))\n",
    "print \"Stop Word | Acuracia Random Forest: {}\".format(accuracy_score(y_test, rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##stop words e stemming\n",
    "stopWords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_all_bag_DF = pd.DataFrame(columns=['TWEET'])\n",
    "\n",
    "for linha in X_all:  \n",
    "    words = word_tokenize(linha)\n",
    "    novalinha = \"\"\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            novalinha+=ps.stem(w)+\" \"\n",
    "    X_all_bag_DF.loc[len(X_all_bag_DF)] = novalinha\n",
    "\n",
    "X_all_bag = X_all_bag_DF['TWEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X_all_bag).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_all, train_size=0.7)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Word e Stemming | Acuracia Multinomial Naive Bayes: 0.778666666667\n",
      "Stop Word e Stemming | Acuracia Gaussian Naive Bayes: 0.668666666667\n",
      "Stop Word e Stemming | Acuracia Random Forest: 0.831333333333\n"
     ]
    }
   ],
   "source": [
    "print \"Stop Word e Stemming | Acuracia Multinomial Naive Bayes: {}\".format(accuracy_score(y_test, mnb.predict(X_test)))\n",
    "print \"Stop Word e Stemming | Acuracia Gaussian Naive Bayes: {}\".format(accuracy_score(y_test, gnb.predict(X_test)))\n",
    "print \"Stop Word e Stemming | Acuracia Random Forest: {}\".format(accuracy_score(y_test, rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
