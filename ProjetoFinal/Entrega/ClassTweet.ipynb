{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTA√á√ÉO DAS BIBLIOTECAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "##TRATAMENTO DOS DADOS\n",
    "import pandas as pd\n",
    "import re ##REGEX\n",
    "\n",
    "##TRATAMENTO DE LINGUAGEM NATURAL\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "##VETORIZAR TEXTO\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#IMPORTA√á√ÉO DE MODELOS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#HOLDOUT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##METRICAS DE AVALIA√á√ÉO\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "##TUNNING DE MODELO\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTA√á√ÉO DOS DADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##IMPORTA√á√ÉO DOS DADOS EXTRAIDOS DO TWEETER PREVIAMENTE\n",
    "data = pd.read_csv(\"C:\\Users\\Adelino\\Desktop\\Roberth\\Cursos\\Nanodegree-Machine_Learning\\Trabalhos\\Projetos\\ProjetoFinal\\Saidas\\Tratadas.csv\", sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DIVIS√ÉO DAS COLUNAS DE FEATURES E TARGET\n",
    "features_columns = data.columns[0]\n",
    "target_columns = data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##CRIA√á√ÉO DOS DATAFRAMES COM AS FEATURES E COM O TARGET\n",
    "X_raw = data[features_columns]\n",
    "y_all = data[target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AJUSTE BASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##CRIA√á√ÉO DE DATAFRAME VAZIO PARA TRATAMENTO DOS DADOS\n",
    "X_all_DF = pd.DataFrame(columns=['TWEET'])\n",
    "\n",
    "for linha in X_raw:  \n",
    "    words = word_tokenize(linha) ##SEPARA POR PALAVRAS\n",
    "    novalinha = \"\"\n",
    "    flag = True\n",
    "    for w in words:\n",
    "        if w != \"RT\": ##N√ÉO UTILIZAR A PALAVRA RT, RETWEET\n",
    "            if re.match('[a-zA-Z0-9_]',w) and flag: ##UTILIZAR APENAS PALAVRAS ALFANUMERICAS\n",
    "                novalinha+=w+\" \" ##RECONSTREI A FRASE SEM RT, SEM @, SEM PONTUA√á√ïES\n",
    "            if w == \"@\": ##VERIFICAR SE √â UM @, SE FOR MARCA PARA N√ÉO UTILIZAR A PROXIMA PALAVRA,\n",
    "                            ##POIS TRATA-SE DE SITA√á√ÉO DE USUARIO \n",
    "                flag = False\n",
    "            else:\n",
    "                flag = True\n",
    "    X_all_DF.loc[len(X_all_DF)] = novalinha ## INCLUI LINHA NOVA, TRATADA, NO DATAFRAME NOVO\n",
    "\n",
    "X_all = X_all_DF['TWEET'] ##CRIA NOVO DATAFRAME PARA SER UTILIZADO COMO FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Out here trying to find the next bitcoin to tr...\n",
       "1       Let farm bitcoins for free together https Ever...\n",
       "2       The Japanese government said today that inspec...\n",
       "3       With this project we will help undervalued coi...\n",
       "4       Op-ed How Decentralized Protocols Are Threaten...\n",
       "5       Solar Exclusive No samples One beat One artist...\n",
       "6       Bitcoin Cash Surges To Fresh All-Time High Abo...\n",
       "7       New bitcoin block 0000000000000000000cc1416a71...\n",
       "8       Bitcoin Bitcoinbet LaVine took flight against ...\n",
       "9       I Will Promote Your Bitcoin Ad Or Link Via Soc...\n",
       "10                       Inheritance law meets btc https \n",
       "11      Bitcoin Gold BTG successfully launch mainned a...\n",
       "12      After you receive the update with LCC read rel...\n",
       "13      I just got my bitcoin seized Send me more bitc...\n",
       "14      Ethereum Developer Resigns as Code Editor Citi...\n",
       "15      Bitcoin Gold BTG successfully launch mainned a...\n",
       "16      JPMorgan Praises Bitcoin ETFs Litecoin Cash Sc...\n",
       "17      I added a video to a playlist https Earn 1 Dog...\n",
       "18      a millionaire who knows how to trade Bitcoin u...\n",
       "19      BTCUSD Bitcoin price analysis BTC/USD sideline...\n",
       "20                          The alchemy of bitcoin https \n",
       "21      Earn 0.00000005+ BTC instantly 1 Retweet this ...\n",
       "22      Why are these Forex amp Bitcoin traders so des...\n",
       "23      Bitcoin LiteCoin Ethereum and Ripple prices to...\n",
       "24      Need support to improve Trading skill Particip...\n",
       "25              Most popular Bitcoin News auctions https \n",
       "26      BitConnect Again DavorCoin Price Dives After L...\n",
       "27      Bitcoin Breaks Above 11,000 Threshold in Fourt...\n",
       "28      Eur USD SHORT https crytotradebtc bitcoin btc ...\n",
       "29      I got my magic spacesuit on let goto moon btc ...\n",
       "                              ...                        \n",
       "4970    Tonight on the news Fancy man in a suit and ma...\n",
       "4971    Bitcoin Price Technical Analysis for 02/14/201...\n",
       "4972    Moody Bitcoin futures volatility mitigated by ...\n",
       "4973    New post BoE Carney says Bitcoin has much fail...\n",
       "4974    New post Bitcoin Today Prices Rally Ahead of C...\n",
       "4975    BoE Governor Mark Carney says Bitcoin failed a...\n",
       "4976    Trader Uses Company Crypto to Fund Gambling Ge...\n",
       "4977    Failed China financial products drew investors...\n",
       "4978    Bitcoin Price Surges 57 Off Monthly Lows- Bull...\n",
       "4979    All Crypto s now are just a proxy for risk Ris...\n",
       "4980    Bitcoin Price Technical Analysis for 02/14/201...\n",
       "4981    Bitcoin Morning Brief The Breakout of 9k has B...\n",
       "4982    Bitcoin Price Technical Analysis for 02/14/201...\n",
       "4983    Lovely crypto breakouts for the majors Still a...\n",
       "4984    Intriguing perspective on potential use cases ...\n",
       "4985    Lightning Network failed right here apparently...\n",
       "4986    Trader charged with defrauding company of 2M i...\n",
       "4987    10K on cards bitcoin BTCUSD inverse head and s...\n",
       "4988    JUST IN Bank of England Carney says Bitcoin ha...\n",
       "4989    The Cryptocurrency Codex Low cost amp low risk...\n",
       "4990    So wrote a pretty awesome piece about food fra...\n",
       "4991    I made 7 Figure income in just 12 monthsüí≤ Ris...\n",
       "4992                                      BCASH is fraud \n",
       "4993    Rabobank Fined 369M for Money Laundering After...\n",
       "4994                            Is Bitcoin at risk https \n",
       "4995    Trading Ideas Monero VS Bitcoin Downside Risk ...\n",
       "4996    Sending Bitcoin on Lightning The Early Risky W...\n",
       "4997    Don t trust anyone else to trade for you Manag...\n",
       "4998    BoE Carney says Bitcoin has much failed as cur...\n",
       "4999    Moody Bitcoin Volatility Likely Wo n't Hurt CM...\n",
       "Name: TWEET, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CRIA√á√ÉO DE BAG OF WORDS, REMOVENDO STOP WORDS E REDUZINDO PARA O RADICAL (STEMMING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english')) ## STOPWORDS DA BIBLIOTECA NLTK\n",
    "ps = PorterStemmer() ##STEMMING DA BIBLIOTECA NLTK\n",
    "vectorizer = CountVectorizer() ##INSTANCIA PARA VETORIZAR E CONTAR AS PALAVRAS EXISTENTES NO TWEET\n",
    "\n",
    "X_all_bag_DF = pd.DataFrame(columns=['TWEET']) ## NOVO DATAFRAME PARA UTILIZA√á√ÉO DE BAG OF WORDS\n",
    "\n",
    "for linha in X_all:  \n",
    "    words = word_tokenize(linha) ##SEPARA POR PALAVRAS \n",
    "    novalinha = \"\"\n",
    "    for w in words:\n",
    "        if w not in stopWords: ##VERIFICAR SE ESTA NA LISTA DE STOPWORDS, SE N√ÉO ESTIVER CONTINUA\n",
    "            novalinha+=ps.stem(w)+\" \" ##INCLUI O RADICAL DA PALAVRA EM UMA NOVA LINHA\n",
    "    X_all_bag_DF.loc[len(X_all_bag_DF)] = novalinha ##INCLUI LINHA NO NOVO DATAFRAME\n",
    "\n",
    "X_all_bag = X_all_bag_DF['TWEET'] ##CRIA NOVO DATAFRAME PARA SER UTILIZADO COMO FEATURES,\n",
    "                                    ###J√Å EXCLUINDO STOPWORDS E REDUZINDO AS PALAVRAS PARA SEU RADICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##VETORIZAR E CONTAR AS PALAVRAS EXISTENTES NO TWEET E ARMAZENAR NA VARIAVEL X\n",
    "X = vectorizer.fit_transform(X_all_bag).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREINAMENTO DE MODELOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "##SEPARAR OS DADOS ENTRE TREINO E TESTE RESPEITANDO 75% DA BASE COMO TREINO\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_all, train_size=0.75)\n",
    "\n",
    "#INSTANCIA DOS 3 MODELOS A SEREM TREINADOS E TESTADOS\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TREINAMENTO DOS 3 MODELOS ACIMA, DE FORMA DEFAULT\n",
    "mnb.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score Multinomial Naive Bayes: 0.7688\n",
      "F1_Score Gaussian Naive Bayes: 0.6808\n",
      "F1_Score Random Forest: 0.836\n"
     ]
    }
   ],
   "source": [
    "##AVALIA√á√ÉO DOS F1_SCORE DE CADA MODELO\n",
    "print \"F1_Score Multinomial Naive Bayes: {}\".format(f1_score(y_test, mnb.predict(X_test), average='micro'))\n",
    "print \"F1_Score Gaussian Naive Bayes: {}\".format(f1_score(y_test, gnb.predict(X_test), average='micro'))\n",
    "print \"F1_Score Random Forest: {}\".format(f1_score(y_test, rfc.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TUNNING DO MELHOR MODELO ACIMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O par√¢metro 'n_estimators' √© 100 para o modelo √≥timo.\n",
      "O par√¢metro 'max_depth' √© 100 para o modelo √≥timo.\n",
      "O par√¢metro 'min_samples_leaf' √© 1 para o modelo √≥timo.\n",
      " \n",
      "O modelo calibrado tem F1 de 0.9368 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.8584 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "##MELHOR F1_SCORE ACIMA = RANDOM FOREST\n",
    "clf = RandomForestClassifier() #NOVA INSTANCIA DE RANDOM FOREST\n",
    "\n",
    "##DEFINI√á√ÉO DOS PARAMENTROS A SEREM TESTADOS NO RANDOM FOREST\n",
    "parameters = {'n_estimators' : [1, 10, 100],\n",
    "               'criterion' : ['gini', 'entropy'],\n",
    "               'max_depth' : [1, 10, 100],\n",
    "               'min_samples_split' : [2, 5, 10],\n",
    "               'min_samples_leaf' : [1, 5, 10]}\n",
    "\n",
    "grid_obj = GridSearchCV(clf, parameters, cv=10)##CRIA OBJETO DE GRIDSEARCH COM O CLASSIFICADOR E \n",
    "                                                ##PARAMETROS ACIMA E CROSSVALIDATION DE 10 FOLDS\n",
    "grid_obj = grid_obj.fit(X_train, y_train)##RODAR O GRIDSEARCH PARA IDENTIFICAR OS MELHORES PARAMETROS E\n",
    "                                            ##TREINAR O MODELO COM ELES\n",
    "\n",
    "clf = grid_obj.best_estimator_ ##CRIA NOVO CLASSIFICADOR COM O MELHOR RESULTADO DO GRIDSEARCH ACIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O par√¢metro 'n_estimators' √© 100 para o modelo √≥timo.\n",
      "O par√¢metro 'max_depth' √© 100 para o modelo √≥timo.\n",
      "O par√¢metro 'min_samples_leaf' √© 1 para o modelo √≥timo.\n",
      "O par√¢metro 'criterion' √© gini para o modelo √≥timo.\n",
      "O par√¢metro 'min_samples_split' √© 5 para o modelo √≥timo.\n",
      " \n",
      "O modelo calibrado tem F1 de 0.9368 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.8584 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "##VERIFICAR QUAIS FORAM OS MELHORES VALORES DOS PARAMETROS\n",
    "print \"O par√¢metro 'n_estimators' √© {} para o modelo √≥timo.\".format(clf.get_params()['n_estimators'])\n",
    "print \"O par√¢metro 'max_depth' √© {} para o modelo √≥timo.\".format(clf.get_params()['max_depth'])\n",
    "print \"O par√¢metro 'min_samples_leaf' √© {} para o modelo √≥timo.\".format(clf.get_params()['min_samples_leaf'])\n",
    "print \"O par√¢metro 'criterion' √© {} para o modelo √≥timo.\".format(clf.get_params()['criterion'])\n",
    "print \"O par√¢metro 'min_samples_split' √© {} para o modelo √≥timo.\".format(clf.get_params()['min_samples_split'])\n",
    "\n",
    "print \" \"\n",
    "\n",
    "##VERIFICAR O F1_SCORE DO MODELO CALIBRADO COM O BEST ESTIMATOR DO GRIDSEARCH\n",
    "print \"O modelo calibrado tem F1 de {} no conjunto de treinamento.\".format(f1_score(y_train, clf.predict(X_train), average='micro'))\n",
    "print \"O modelo calibrado tem F1 de {} no conjunto de teste.\".format(f1_score(y_test, clf.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CRIAR MODELO BENCHMARK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##BENCHMARK CRIADO COM O DUMMY CLASSIFIER, QUE CLASSIFICA DE FORMA \"BURRA OS TWEETS\"\n",
    "dmc = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmc.fit(X_train, y_train) ##TREINA O BENCKMARK COM OS MESMOS DADOS PASSADOS PARA O MODELO\n",
    "                            ##TREINADO E OTIMIZADO ACIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo benchmark tem F1 de 0.3336 no conjunto de treinamento.\n",
      "O modelo benchmark tem F1 de 0.3376 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "##VERIFICAR O F1_SCORE DO MODELO BENCHMARK\n",
    "print \"O modelo benchmark tem F1 de {} no conjunto de treinamento.\".format(f1_score(y_train, dmc.predict(X_train), average='micro'))\n",
    "print \"O modelo benchmark tem F1 de {} no conjunto de teste.\".format(f1_score(y_test, dmc.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
