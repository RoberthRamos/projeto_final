{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTAÇÃO DAS BIBLIOTECAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "##TRATAMENTO DOS DADOS\n",
    "import pandas as pd\n",
    "import re ##REGEX\n",
    "\n",
    "##TRATAMENTO DE LINGUAGEM NATURAL\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "##VETORIZAR TEXTO\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#IMPORTAÇÃO DE MODELOS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#HOLDOUT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##METRICAS DE AVALIAÇÃO\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "##TUNNING DE MODELO\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTAÇÃO DOS DADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##IMPORTAÇÃO DOS DADOS EXTRAIDOS DO TWEETER PREVIAMENTE\n",
    "data = pd.read_csv(\"C:\\Users\\Adelino\\Desktop\\Roberth\\Cursos\\Nanodegree-Machine_Learning\\Trabalhos\\Projetos\\ProjetoFinal\\Saidas\\Tratadas.csv\", sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DIVISÃO DAS COLUNAS DE FEATURES E TARGET\n",
    "features_columns = data.columns[0]\n",
    "target_columns = data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##CRIAÇÃO DOS DATAFRAMES COM AS FEATURES E COM O TARGET\n",
    "X_raw = data[features_columns]\n",
    "y_all = data[target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AJUSTE BASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CRIAÇÃO DE DATAFRAME VAZIO PARA TRATAMENTO DOS DADOS\n",
    "X_all_DF = pd.DataFrame(columns=['TWEET'])\n",
    "\n",
    "for linha in X_raw:  \n",
    "    words = word_tokenize(linha) ##SEPARA POR PALAVRAS\n",
    "    novalinha = \"\"\n",
    "    flag = True\n",
    "    for w in words:\n",
    "        if w != \"RT\": ##NÃO UTILIZAR A PALAVRA RT, RETWEET\n",
    "            if re.match('[a-zA-Z0-9_]',w) and flag: ##UTILIZAR APENAS PALAVRAS ALFANUMERICAS\n",
    "                novalinha+=w+\" \" ##RECONSTREI A FRASE SEM RT, SEM @, SEM PONTUAÇÕES\n",
    "            if w == \"@\": ##VERIFICAR SE É UM @, SE FOR MARCA PARA NÃO UTILIZAR A PROXIMA PALAVRA, POIS TRATA-SE DE SITAÇÃO DE USUARIO \n",
    "                flag = False\n",
    "            else:\n",
    "                flag = True\n",
    "    X_all_DF.loc[len(X_all_DF)] = novalinha ## INCLUI LINHA NOVA, TRATADA, NO DATAFRAME NOVO\n",
    "\n",
    "X_all = X_all_DF['TWEET'] ##CRIA NOVO DATAFRAME PARA SER UTILIZADO COMO FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CRIAÇÃO DE BAG OF WORDS, REMOVENDO STOP WORDS E REDUZINDO PARA O RADICAL (STEMMING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english')) ## STOPWORDS DA BIBLIOTECA NLTK\n",
    "ps = PorterStemmer() ##STEMMING DA BIBLIOTECA NLTK\n",
    "vectorizer = CountVectorizer() ##INSTANCIA PARA VETORIZAR E CONTAR AS PALAVRAS EXISTENTES NO TWEET\n",
    "\n",
    "X_all_bag_DF = pd.DataFrame(columns=['TWEET']) ## NOVO DATAFRAME PARA UTILIZAÇÃO DE BAG OF WORDS\n",
    "\n",
    "for linha in X_all:  \n",
    "    words = word_tokenize(linha) ##SEPARA POR PALAVRAS \n",
    "    novalinha = \"\"\n",
    "    for w in words:\n",
    "        if w not in stopWords: ##VERIFICAR SE ESTA NA LISTA DE STOPWORDS, SE NÃO ESTIVER CONTINUA\n",
    "            novalinha+=ps.stem(w)+\" \" ##INCLUI O RADICAL DA PALAVRA EM UMA NOVA LINHA\n",
    "    X_all_bag_DF.loc[len(X_all_bag_DF)] = novalinha ##INCLUI LINHA NO NOVO DATAFRAME\n",
    "\n",
    "X_all_bag = X_all_bag_DF['TWEET'] ##CRIA NOVO DATAFRAME PARA SER UTILIZADO COMO FEATURES, JÁ EXCLUINDO STOPWORDS E REDUZINDO AS PALAVRAS PARA SEU RADICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##VETORIZAR E CONTAR AS PALAVRAS EXISTENTES NO TWEET E ARMAZENAR NA VARIAVEL X\n",
    "X = vectorizer.fit_transform(X_all_bag).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREINAMENTO DE MODELOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelino\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "##SEPARAR OS DADOS ENTRE TREINO E TESTE RESPEITANDO 75% DA BASE COMO TREINO\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_all, train_size=0.75)\n",
    "\n",
    "#INSTANCIA DOS 3 MODELOS A SEREM TREINADOS E TESTADOS\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TREINAMENTO DOS 3 MODELOS ACIMA, DE FORMA DEFAULT\n",
    "mnb.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score Multinomial Naive Bayes: 0.7688\n",
      "F1_Score Gaussian Naive Bayes: 0.6808\n",
      "F1_Score Random Forest: 0.836\n"
     ]
    }
   ],
   "source": [
    "##AVALIAÇÃO DOS F1_SCORE DE CADA MODELO\n",
    "print \"F1_Score Multinomial Naive Bayes: {}\".format(f1_score(y_test, mnb.predict(X_test), average='micro'))\n",
    "print \"F1_Score Gaussian Naive Bayes: {}\".format(f1_score(y_test, gnb.predict(X_test), average='micro'))\n",
    "print \"F1_Score Random Forest: {}\".format(f1_score(y_test, rfc.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TUNNING DO MELHOR MODELO ACIMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O parâmetro 'n_estimators' é 100 para o modelo ótimo.\n",
      "O parâmetro 'max_depth' é 100 para o modelo ótimo.\n",
      "O parâmetro 'min_samples_leaf' é 1 para o modelo ótimo.\n",
      " \n",
      "O modelo calibrado tem F1 de 0.9368 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.8584 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "##MELHOR F1_SCORE ACIMA = RANDOM FOREST\n",
    "clf = RandomForestClassifier() #NOVA INSTANCIA DE RANDOM FOREST\n",
    "\n",
    "##DEFINIÇÃO DOS PARAMENTROS A SEREM TESTADOS NO RANDOM FOREST\n",
    "parameters = {'n_estimators' : [1, 10, 100],\n",
    "               'criterion' : ['gini', 'entropy'],\n",
    "               'max_depth' : [1, 10, 100],\n",
    "               'min_samples_split' : [2, 5, 10],\n",
    "               'min_samples_leaf' : [1, 5, 10]}\n",
    "\n",
    "grid_obj = GridSearchCV(clf, parameters, cv=10)##CRIA OBJETO DE GRIDSEARCH COM O CLASSIFICADOR E PARAMETROS ACIMA E CROSSVALIDATION DE 10 FOLDS\n",
    "grid_obj = grid_obj.fit(X_train, y_train)##RODAR O GRIDSEARCH PARA IDENTIFICAR OS MELHORES PARAMETROS E TREINAR O MODELO COM ELES\n",
    "\n",
    "clf = grid_obj.best_estimator_ ##CRIA NOVO CLASSIFICADOR COM O MELHOR RESULTADO DO GRIDSEARCH ACIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O parâmetro 'n_estimators' é 100 para o modelo ótimo.\n",
      "O parâmetro 'max_depth' é 100 para o modelo ótimo.\n",
      "O parâmetro 'min_samples_leaf' é 1 para o modelo ótimo.\n",
      "O parâmetro 'criterion' é gini para o modelo ótimo.\n",
      "O parâmetro 'min_samples_split' é 5 para o modelo ótimo.\n",
      " \n",
      "O modelo calibrado tem F1 de 0.9368 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.8584 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "##VERIFICAR QUAIS FORAM OS MELHORES VALORES DOS PARAMETROS\n",
    "print \"O parâmetro 'n_estimators' é {} para o modelo ótimo.\".format(clf.get_params()['n_estimators'])\n",
    "print \"O parâmetro 'max_depth' é {} para o modelo ótimo.\".format(clf.get_params()['max_depth'])\n",
    "print \"O parâmetro 'min_samples_leaf' é {} para o modelo ótimo.\".format(clf.get_params()['min_samples_leaf'])\n",
    "print \"O parâmetro 'criterion' é {} para o modelo ótimo.\".format(clf.get_params()['criterion'])\n",
    "print \"O parâmetro 'min_samples_split' é {} para o modelo ótimo.\".format(clf.get_params()['min_samples_split'])\n",
    "\n",
    "print \" \"\n",
    "\n",
    "##VERIFICAR O F1_SCORE DO MODELO CALIBRADO COM O BEST ESTIMATOR DO GRIDSEARCH\n",
    "print \"O modelo calibrado tem F1 de {} no conjunto de treinamento.\".format(f1_score(y_train, clf.predict(X_train), average='micro'))\n",
    "print \"O modelo calibrado tem F1 de {} no conjunto de teste.\".format(f1_score(y_test, clf.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CRIAR MODELO BENCHMARK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BENCHMARK CRIADO COM O DUMMY CLASSIFIER, QUE CLASSIFICA DE FORMA \"BURRA OS TWEETS\"\n",
    "dmc = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmc.fit(X_train, y_train) ##TREINA O BENCKMARK COM OS MESMOS DADOS PASSADOS PARA O MODELO TREINADO E OTIMIZADO ACIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo benchmark tem F1 de 0.3336 no conjunto de treinamento.\n",
      "O modelo benchmark tem F1 de 0.3376 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "##VERIFICAR O F1_SCORE DO MODELO BENCHMARK\n",
    "print \"O modelo benchmark tem F1 de {} no conjunto de treinamento.\".format(f1_score(y_train, dmc.predict(X_train), average='micro'))\n",
    "print \"O modelo benchmark tem F1 de {} no conjunto de teste.\".format(f1_score(y_test, dmc.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
